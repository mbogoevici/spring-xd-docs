=== Introduction
One of the features that XD offers is the ability to launch and monitor batch jobs using  http://www.springsource.org/spring-batch[Spring Batch].
This purpose of this section is to show you how to create a sample tasklet as well as create, schedule and monitor a job.

=== Setting up a simple Batch Job

==== Creating the Tasklet

We will create a very simple http://static.springsource.org/spring-batch/reference/html/configureStep.html#taskletStep[Tasklet]. The sole purpose of this Tasklet is to print out "Hello Spring XD!".  Note, you can find the the source code and the maven build files for this example in the https://github.com/SpringSource/spring-xd-samples[Spring XD Samples] repository.

[source,java]
----
package org.springframework.springxd.samples.batch;

import org.springframework.batch.core.StepContribution;
import org.springframework.batch.core.scope.context.ChunkContext;
import org.springframework.batch.core.step.tasklet.Tasklet;
import org.springframework.batch.repeat.RepeatStatus;

public class HelloSpringXDTasklet implements Tasklet {

	public RepeatStatus execute(StepContribution contribution,
			ChunkContext chunkContext) throws Exception {

		System.out.println("Hello Spring XD!");

		return RepeatStatus.FINISHED;
	}
}
----

Please ensure that you deploy this class as part of a Jar file to the Spring XD *${xd.home}/lib* folder. Once you restart the Spring XD container the class will be automatically added to the classpath and thus made available.  If you are building from the sample repository do the following in the directory `spring-xd-samples/batch-simple`

* `mvn package`
* `cp ./target/springxd-batch-simple-1.0.0.BUILD-SNAPSHOT.jar $XD_HOME/lib`

==== Setting Up the Application Context

Under *modules/job*, in the Spring XD home directory, please create the following XML application context file named *myjob.xml*: 

[source,xml]
----

<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:int="http://www.springframework.org/schema/integration"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:batch="http://www.springframework.org/schema/batch"
	xsi:schemaLocation="http://www.springframework.org/schema/beans
		http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/integration
		http://www.springframework.org/schema/integration/spring-integration.xsd
		http://www.springframework.org/schema/batch
		http://www.springframework.org/schema/batch/spring-batch.xsd">

	<batch:job id="job">
		<batch:step id="helloSpringXDStep">
			<batch:tasklet ref="helloSpringXDTasklet" />
		</batch:step>
	</batch:job>

	<bean id="helloSpringXDTasklet"
		class="org.springframework.springxd.samples.batch.HelloSpringXDTasklet" />

</beans>
----

This context file must contain single batch job whose id is `job`.

If you are building from the sample repository do the following in the directory `spring-xd-samples/batch-simple`

* `cp ./src/main/resources/myjob.xml $XD_HOME/modules/job/`

=== Creating your Job
Now from the XD-Shell let's create a job.  This is done by executing a job create command composed of:

* name - the "name" that will be associated with the Job 
* definition - the name of the context file that describes the tasklet.

So using our example above where we declared a myjob.xml that contains the context for our task, so to create the job will look like:
----
xd:> job create --name helloSpringXD --definition "myjob"
----
In the logging output of the XDContainer you should see the following:
----
14:17:46,793  INFO http-bio-8080-exec-5 job.JobPlugin:87 - Configuring module with the following properties: {numberFormat=, dateFormat=, makeUnique=true, xd.stream.name=helloSpringXD}
14:17:46,837  INFO http-bio-8080-exec-5 module.SimpleModule:140 - initialized module: SimpleModule [name=myjob, type=job, group=helloSpringXD, index=0]
14:17:46,840  INFO http-bio-8080-exec-5 module.SimpleModule:154 - started module: SimpleModule [name=job, type=job, group=helloSpringXD, index=0]
14:17:46,840  INFO http-bio-8080-exec-5 module.ModuleDeployer:152 - launched job module: helloSpringXD:myjob:0
----
=== Launching a job
XD uses triggers as well as regular event flow to launch the batch jobs.  So in this section we will cover how to:

* Launch the Batch Job Ad-hoc
* Launch the Batch Job using a named Cron-Trigger
* Launch the Batch Job as sink.

==== Ad-hoc
To launch a job one time, use the launch option of the job command.  So going back to our example above, we've created a job module instance named helloSpringXD.  Launching that Job Module Instance would look like:
----
xd:> job launch helloSpringXD
----
In the logging output of the XDContainer you should see the following
----
16:45:40,127  INFO http-bio-9393-exec-1 job.JobPlugin:98 - Configuring module with the following properties: {numberFormat=, dateFormat=, makeUnique=true, xd.stream.name=myjob}
16:45:40,185  INFO http-bio-9393-exec-1 module.SimpleModule:140 - initialized module: SimpleModule [name=job, type=job, group=myjob, index=0 @3a9ecb9d]
16:45:40,198  INFO http-bio-9393-exec-1 module.SimpleModule:161 - started module: SimpleModule [name=job, type=job, group=myjob, index=0 @3a9ecb9d]
16:45:40,199  INFO http-bio-9393-exec-1 module.ModuleDeployer:161 - deployed SimpleModule [name=job, type=job, group=myjob, index=0 @3a9ecb9d]
Hello Spring XD!
----
To re-launch the job just execute the launch command.
For example:
----
xd:> job launch helloSpringXD
----
==== Launch the Batch using Cron-Trigger
To launch a batch job based on a cron scheduler is done by creating a stream using the cron-trigger source.  

----
xd:> stream create --name cronStream --definition "cron-trigger --cron='0/5 * * * * *'  > queue:job:myCronJob" 

----
A batch job can receive parameters from a source (in this case a trigger) or process. A trigger uses the --payload expression to declare its payload.
----
xd:> stream create --name cronStream --definition "cron-trigger --cron='0/5 * * * * *'  --payload='{"param1":"Kenny"}' > queue:job:myCronJob"  
----
NOTE: The payload content must be in a JSON-based map representation.

To pause/stop future scheduled jobs from running for this stream, the stream must be undeployed for example:
----
xd:> stream undeploy --name cronStream
----
==== Launch the Batch using a Fixed-Delay-Trigger
A fixed-delay-trigger is used to launch a Job on a regular interval.  Using the --fixedDelay parameter you can set up the number of seconds between executions.  In the example below we are running myXDJob every 10 seconds and passing it a payload containing a single attribute.
----
xd:> stream create --name fdStream --definition "fixed-delay-trigger --payload='{"param1":"fixedDelayKenny"}' --fixedDelay=10 > queue:job:myXDJob" 
----
To pause/stop future scheduled jobs from running for this stream, you must undeploy the stream for example:
----
xd:> stream undeploy --name cronStream
----
==== Launch job as a part of event flow
A batch job is always used as a sink, with that being said it can receive messages from sources (other than triggers) and processors. In the case below we see that the user has created a http source (http source receives http posts and passes the payload of the http message to the next module in the stream) that will pass the http payload to the "myHttpJob".

----
 stream create --name jobStream --definition "http > queue:job:myHttpJob"
----
To test the stream you can execute a http post, like the following:
----
xd:> http post --target http://localhost:9000 --data "{"param1":"fixedDelayKenny"}"
----
=== Retrieve job notifications
XD offers the facilities to capture the notifications that are sent from the job as it is executing.  
 
Notifications include: 

* Job Execution Listener
* Chunk Listener
* Item Listener
* Step Execution Listener
* Skip Listener

In this example, the job will send notifications to the log. 
----
stream create --name jobNotifications --definition ":myHttpJob-notifications >log"
----
In the logging output of the container you should see something like the following when the job completes:
----
15:26:30,029  WARN task-scheduler-5 logger.jobNotifications:145 - JobExecution: id=1, version=2, startTime=Wed Aug 28 15:26:30 EDT 2013, endTime=Wed Aug 28 15:26:30 EDT 2013, lastUpdated=Wed Aug 28 15:26:30 EDT 2013, status=COMPLETED, exitStatus=exitCode=COMPLETED;exitDescription=, job=[JobInstance: id=1, version=0, Job=[myHttpJob.job]], jobParameters=[{random=0.49881213192780494}]
----

=== Removing Batch Jobs

Batch Jobs can be deleted by executing:

----
xd:> job destroy helloSpringXD
----

Alternatively, one can just undeploy the job, keeping its definition for a future redeployment:

----
xd:> job undeploy helloSpringXD
----


=== Pre-Packaged Batch Jobs

Spring XD comes with several batch import and export modules. You can run them out of the box or use them as a basis for building your own custom modules.

==== Import Files to HDFS (`filehdfs`)

This module is designed to be driven by a stream. It imports data from CSV files and requires that you supply a list of named columns for the data using the `names` parameter. For example:

----
xd:> job create myjob --definition "filehdfs --names=forename,surname,address"
----

You would then use a stream with a file source to scan a directory for files and drive the job. A separate file will be started for each job found:

----
xd:> stream create csvStream --definition "file --ref=true --dir=/mycsvdir --pattern=*.csv > queue:job:myjob"
----

==== Import Files to JDBC (`filejdbc`)

A module which loads CSV files from a directory into a JDBC table using a single batch job. By default it uses the file `config/batch-jdbc-import.properties` to configure the module and stores data in the internal HSQL DB which is used by Spring Batch. The job should be defined with the `resources` parameter defining the files which should be loaded. It also requires a `names` parameter (for the CSV field names) and these should match the database column names into which the data should be stored. You can either pre-create the database table or the module will try to create it for you when it is loaded. The table intitialization is configured in a similar way to the JDBC sink and uses the same parameters. The default table name is the job name and can be cumstomized by setting the `tableName` parameter. As an example, if you run the command

----
xd:> job create myjob --definition "filejdbc --resources=/mycsvdir/*.csv --names=forename,surname,address --tableName=people"
----

it will create the table "people" in the database with three varchar columns called "forename", "surname" and "address". When you launch the job it will load the files matching the resources pattern and write the data to this table.

==== HDFS to JDBC Export (`hdfsjdbc`)

This module functions very similarly to the `filejdbc` one except that the resources you specify should actually be in HDFS, rather than the OS filesystem. Other than that the syntax is the same

----
xd:> job create myjob --definition "hdfsjdbc --resources=/data/*.log --names=forename,surname,address --tableName=people"
----

there is also a limitation in that the database table must be created manually. This is due to a bug in Spring Hadoop and will be fixed in the future.

==== HDFS to MongoDB Export (`hdfsmongodb`)

Exports CSV data from HDFS and stores it in a MongoDB collection which defaults to the stream name. This can be overridden with the `collectionName` parameter. The job is configured using the file `config/batch-mongo-import.properties`. Once again, the field names should be defined by supplying the `names` parameter. The data is converted internally to a Spring XD `Tuple` and the collection items will have an `id` matching the tuple's UUID. You can override this by setting the `idField` parameter to one of the field names if desired.

An example:

----
xd:> job create myjob --definition "hdfsmongodb --resources=/data/*.log --names=employeeId,forename,surname,address --idField=employeeId --collectionName=people"
----

