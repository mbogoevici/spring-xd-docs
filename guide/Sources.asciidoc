=== Introduction
In this section we will show some variations on input sources.  As a prerequisite start the XD Container
as instructed in the link:Getting-Started#getting-started[Getting Started] page.

The Sources covered are

* <<http, HTTP>>
* <<tail, Tail>>
* <<twittersearch, Twitter Search>>
* <<twitterstream, Twitter Stream>>
* <<gemfire-cq,Gemfire CQ>>
* <<syslog, Syslog>>
* <<tcp, TCP>>
* <<time, Time>>
* <<mqtt, MQTT>>

Future releases will provide support for RabbitMQ, JMS, and other currently available Spring Integration Adapters.  For information on how to adapt an existing Spring Integration Adapter for use in Spring XD see the section link:Creating-a-Source-Module#creating-a-source-module[Creating a Source Module].

The following sections show a mix of Spring XD shell and plain Unix shell commands, so if you are trying them out, you should open two separate terminal prompts, one running the XD shell and one to enter the standard commands for sending HTTP data, creating directories, reading files and so on.

[[http]]
=== HTTP

To create a stream definition in the server using the XD shell

    http://localhost:8080:> stream create --name httptest --definition "http | file"

Make sure the default output directory exists

     $ mkdir -p /tmp/xd/output/

Post some data to the http server on the default port of 9000

     http://localhost:8080:> http post --target http://localhost:9000 --data "hello world"

See if the data ended up in the file

     $ cat /tmp/xd/output/httptest

==== HTTP with options

The http source has one option

port:: The http port where data will be posted *(default: `9000`)*

Here is an example 

    http://localhost:8080:> stream create --name httptest9020 --definition "http --port=9020 | file"

Post some data to the new port

    http://localhost:8080:> http post --target http://localhost:9020 --data "hello world"

    $ cat /tmp/xd/output/httptest9020

[[tail]]
=== Tail

Make sure the default input directory exists

     $ mkdir -p /tmp/xd/input

Create an empty file to tail (this is not needed on some platforms such as Linux)

     touch /tmp/xd/input/tailtest  

To create a stream definition using the XD shell

    http://localhost:8080:> stream create --name tailtest --definition "tail | file"

Send some text into the file being monitored 

     $ echo blah >> /tmp/xd/input/tailtest

See if the data ended up in the file
     
     $ cat /tmp/xd/output/tailtest

==== Tail with options

The tail source has 3 options:

name:: the absolute path to the file to tail *(default: `/tmp/xd/input/<streamName>`)*
lines:: the number of lines from the end of an existing file to tail *(default: `0`)*
delay:: on platforms that don't wait for a missing file to appear, how often (ms) to look for the file *(default: `5000`)*

Here is an example 

     http://localhost:8080:> stream create --name tailtest --definition "tail --name=/tmp/foo | file --name=bar"

     $ echo blah >> /tmp/foo

     $ cat /tmp/xd/output/bar


==== Tail Status Events

Some platforms, such as linux, send status messages to `stderr`. The tail module sends these events to a logging adapter, at WARN level; for example...

----
[message=tail: cannot open `/tmp/xd/input/tailtest' for reading: No such file or directory, file=/tmp/xd/input/tailtest]
[message=tail: `/tmp/xd/input/tailtest' has become accessible, file=/tmp/xd/input/tailtest]
----

[[twittersearch]]
=== Twitter Search

The twittersearch source has three required parameters

query:: The query that will be run against Twitter *(required)*

consumerKey:: An application consumer key issued by twitter

consumerSecret:: The secret corresponding to the `consumerKey` 

To get a `consumerKey` and `consumerSecret` you need to register a twitter application. If you don't already have one set up, you can create an app at the https://dev.twitter.com/apps[Twitter Developers] site to get these credentials.

To create a stream definition in the server using the XD shell

    http://localhost:8080:> stream create --name springone2gx --definition "twittersearch --consumerKey=<your_key> --consumerSecret=<your_secret> --query='#springone2gx' | file"

Make sure the default output directory for the `file` sink exists

     $ mkdir -p /tmp/xd/output/

Let the twittersearch run for a little while and then check to see 
if some data ended up in the file

     $ cat /tmp/xd/output/springone2gx

TIP: For both `twittersearch` and `twitterstream` you can fill in in the `conf/twitter.properties` file instead of using the DSL parameters to supply keys and secrets.

[[twitterstream]]
=== Twitter Stream

This source ingests data from Twitter's https://dev.twitter.com/docs/streaming-apis/streams/public[streaming] API. It uses the https://dev.twitter.com/docs/streaming-apis/streams/public[sample and filter] stream endpoints rather than the full "firehose" which needs special access. The endpoint used will depend on the parameters you supply in the stream definition (some are specific to the filter endpoint).

You need to supply all keys and secrets (both consumer and accessToken) to authenticate for this source, so it is easiest if you just add these to the `conf/twitter.properties` file. Stream creation is then straightforward:

    http://localhost:8080:> stream create --name tweets --definition "twitterstream | file"

The parameters available are pretty much the same as those listed in the https://dev.twitter.com/docs/streaming-apis/parameters[API docs] and unless otherwise stated, the accepted formats are the same.

 * https://dev.twitter.com/docs/streaming-apis/parameters#delimited[delimited] - set to `true` to get length delimiters in the stream data (defaults to `false`).

 * https://dev.twitter.com/docs/streaming-apis/parameters#stall_warnings[stallWarnings] - set to `true` to enable stall warnings (defaults to `false`).
 * https://dev.twitter.com/docs/streaming-apis/parameters#filter_level[filterLevel]
 * https://dev.twitter.com/docs/streaming-apis/parameters#language[language]
 * https://dev.twitter.com/docs/streaming-apis/parameters#follow[follow]
 * https://dev.twitter.com/docs/streaming-apis/parameters#track[track]
 * https://dev.twitter.com/docs/streaming-apis/parameters#locations[locations]

[[gemfire-cq]]
=== GemFire Continuous Query (CQ)
Continuous query allows client applications to create a GemFire query using Object Query Language(OQL) and register a CQ listener which subscribes to the query and is notified every time the query 's result set changes. The _gemfire_cq_ source registers a CQ which will post CQEvent messages to the stream. 

==== Launching the XD GemFire Server
This source requires a cache server to be running in a separate process and its host and port must be known (NOTE: GemFire locators are not supported yet). The XD distribution includes a GemFire server executable suitable for development and test purposes. This is a Java main class that runs with a Spring configured cache server. The configuration is passed as a command line argument to the server's main method. The configuration includes a cache server port and one or more configured region. XD includes a sample cache configuration called  https://github.com/SpringSource/spring-xd/blob/master/spring-xd-gemfire-server/config/cq-demo.xml[cq-demo]. This starts a server on port 40404 and creates a region named _Stocks_. A Logging cache listener is configured  for the region to log region events.  (TBD: describe launch script)

==== Options

The qemfire-cq source has the following options

query:: The query string in Object Query Language(OQL) *(required, String)*
gemfireHost:: The host on which the GemFire server is running. *(default: `localhost`)*
gemfirePort:: The port on which the GemFire server is running. *(default: `40404`)*

Here is an example. Create two streams: One to write http messages to a Gemfire region named _Stocks_, and another to execute the CQ.

    http://localhost:8080:> stream create --name stocks --definition "http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')" 
    http://localhost:8080:> stream create --name cqtest --definition "gemfire-cq --query=Select * from /Stocks where symbol='VMW' | file"

Now send some messages to the stocks stream.

     http://localhost:8080:> http post --target http://localhost:9090 --data "{"symbol":"VMW", "price":73}"
     http://localhost:8080:> http post --target http://localhost:9090 --data "{"symbol":"VMW", "price":78}"
     http://localhost:8080:> http post --target http://localhost:9090 --data "{"symbol":"VMW", "price":80}"

The _cqtest_ stream is now listening for any stock quote updates for VMW. Presumably, another process is updating the cache. You may create a separate stream to test this (see https://github.com/SpringSource/spring-xd/wiki/GemfireServer[GemfireServer] for instructions).

As updates are posted to the cache you should see them captured in the output file:

    $cat /tmp/xd/output/cqtest

    CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=VMW; value=PDX[1,__GEMFIRE_JSON]{price=73, symbol=VMW}]
    CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=UPDATE; key=VMW; value=PDX[1,__GEMFIRE_JSON]{price=78, symbol=VMW}]
    CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=UPDATE; key=VMW; value=PDX[2,__GEMFIRE_JSON]{price=80, symbol=VMW}]


[[syslog]]
=== Syslog

Two syslog sources are provided: `syslog-udp` and `syslog-tcp`. They both support the following options:

port:: the port on which the system will listen for syslog messages *(default: `11111`)*

To create a stream definition (using shell command)

    http://localhost:8080:> stream create --name syslogtest --definition "syslog-udp --port=1514 | file"

or

    http://localhost:8080:> stream create --name syslogtest --definition "syslog-tcp --port=1514 | file"

Send a test message to the syslog

     logger -p local3.info -t TESTING "Test Syslog Message"

See if the data ended up in the file
     
     $ cat /tmp/xd/output/syslogtest

Refer to your syslog documentation to configure the syslog daemon to forward syslog messages to the stream; some examples are:

UDP - Mac OSX (syslog.conf) and Ubuntu (rsyslog.conf)

    *.*	@localhost:11111 

TCP - Ubuntu (rsyslog.conf)

    $ModLoad omfwd
    *.*	@@localhost:11111

Restart the syslog daemon after reconfiguring.


[[tcp]]
=== TCP

To create a stream definition in the server, use the following XD shell command

    http://localhost:8080:> stream create --name tcptest --definition "tcp | file"

This will create the default TCP source and send data read from it to the `tcptest` file.

TCP is a streaming protocol and some mechanism is needed to frame messages on the wire. A number of decoders are available, the default being 'CRLF' which is compatible with Telnet.

----
$ telnet localhost 1234
Trying ::1...
Connected to localhost.
Escape character is '^]'.
foo
^]

telnet> quit
Connection closed.
----

See if the data ended up in the file

     $ cat /tmp/xd/output/tcptest

==== TCP with options

The TCP source has the following options

port:: the port on which to listen *(default: `1234`)*
reverse-lookup:: perform a reverse DNS lookup on the remote IP Address *(default: `false`)*
socket-timeout:: the timeout (ms) before closing the socket when no data received *(default: `120000`)*
nio:: whether or not to use NIO. NIO is more efficient when there are many connections. *(default: `false`)*
decoder:: how to decode the stream - see below. *(default: `CRLF`)*
binary:: whether the data is binary (true) or text (false). *(default: `false`)*
charset:: the charset used when converting text to `String`. *(default: `UTF-8`)*

==== Available Decoders

.Text Data

CRLF (default):: text terminated by carriage return (0x0d) followed by line feed (0x0a)
LF:: text terminated by line feed (0x0a)
NULL:: text terminated by a null byte (0x00)
STXETX:: text preceded by an STX (0x02) and terminated by an ETX (0x03)

.Text and Binary Data

RAW:: no structure - the client indicates a complete message by closing the socket
L1:: data preceded by a one byte (unsigned) length field (supports up to 255 bytes)
L2:: data preceded by a two byte (unsigned) length field (up to 2^16^-1 bytes)
L4:: data preceded by a four byte (signed) length field (up to 2^31^-1 bytes)


==== Examples

The following examples all use `echo` to send data to `netcat` which sends the data to the source.

The echo options `-en` allows echo to interpret escape sequences and not send a newline.

.CRLF Decoder

    http://localhost:8080:> stream create --name tcptest --definition "tcp | file"

This uses the default (CRLF) decoder and port 1234; send some data

     $ echo -en 'foobar\r\n' | netcat localhost 1234

See if the data ended up in the file

     $ cat /tmp/xd/output/tcptest

.LF Decoder

     http://localhost:8080:> stream create --name tcptest2 --definition "tcp --decoder=LF | file"

     $ echo -en 'foobar\n' | netcat localhost 1235

     $ cat /tmp/xd/output/tcptest2

.NULL Decoder

     http://localhost:8080:> stream create --name tcptest3 --definition "tcp --decoder=NULL | file"

     $ echo -en 'foobar\x00' | netcat localhost 1236

     $ cat /tmp/xd/output/tcptest3

.STXETX Decoder

     http://localhost:8080:> stream create --name tcptest4 --definition "tcp --decoder=STXETX | file"

     $ echo -en '\x02foobar\x03' | netcat localhost 1237

     $ cat /tmp/xd/output/tcptest4

.RAW Decoder

     http://localhost:8080:> stream create --name tcptest5 --definition "tcp --decoder=RAW | file"

     $ echo -n 'foobar' | netcat localhost 1238

     $ cat /tmp/xd/output/tcptest5

.L1 Decoder

     http://localhost:8080:> stream create --name tcptest6 --definition "tcp --decoder=L1 | file"

     $ echo -en '\x06foobar' | netcat localhost 1239

     $ cat /tmp/xd/output/tcptest6

.L2 Decoder

     http://localhost:8080:> stream create --name tcptest7 --definition "tcp --decoder=L2 | file"

     $ echo -en '\x00\x06foobar' | netcat localhost 1240

     $ cat /tmp/xd/output/tcptest7

.L4 Decoder

     http://localhost:8080:> stream create --name tcptest8 --definition "tcp --decoder=L4 | file"

     $ echo -en '\x00\x00\x00\x06foobar' | netcat localhost 1241

     $ cat /tmp/xd/output/tcptest8

==== Binary Data Example

     http://localhost:8080:> stream create --name tcptest9 --definition "tcp --decoder=L1 | file --binary=true"

Note that we configure the `file` sink with `binary=true` so that a newline is not appended.

     $ echo -en '\x08foo\x00bar\x0b' | netcat localhost 1242

----
$ hexdump -C /tmp/xd/output/tcptest9
00000000  66 6f 6f 00 62 61 72 0b                           |foo.bar.|
00000008
----

[[time]]
=== Time
The time source will simply emit a String with the current time every so often. It supports the following options:

interval:: how often to emit a message, expressed in seconds *(default: `1` second)*
format:: how to render the current time, using SimpleDateFormat *(default: `'yyyy-MM-dd HH:mm:ss'`)*


[[mqtt]]
=== MQTT
The mqtt source connects to an mqtt server and receives telemetry messages.

==== Options

The folllowing options are configured in mqtt.properties in XD_HOME/config

    mqtt.url=tcp://localhost:1883
    mqtt.default.client.id=xd.mqtt.client.id
    mqtt.username=guest
    mqtt.password=guest
    mqtt.default.topic=xd.mqtt.test

The defaults are set up to connect to the RabbitMQ MQTT adapter on localhost.

Note that the client id must be no more than 19 characters; this is because `.src` is added and the id must be no more than 23 characters.

clientId:: Identifies the client - overrides the default above.
topics:: The topics to which the source will subscribe - overrides the default above.
